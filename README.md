# Procedure_Review_Agent
A LangGraph-based AI agent that reviews quality procedures against medical device standards using an evaluator-optimizer pattern.
## Overview

The `procedure_review_agent.py` implements an intelligent quality assurance system that:
- Reviews procedures against ISO 13485, ISO 14971, and IEC 62304 standards
- Uses iterative evaluation and improvement cycles
- Tracks token usage for transparency
- Generates comprehensive DOCX reports

## Architecture

### Core Components

#### 1. QualityReviewAgent
Base agent class with:
- **LLM Integration**: Uses OpenAI GPT-4o-mini model
- **Knowledge Base**: Built-in ISO standards requirements
- **Workflow Management**: LangGraph state machine
- **Token Tracking**: Input/output/total token monitoring

#### 2. EnhancedQualityReviewAgent
Extended version with:
- **Procedure Analysis**: Extracts steps, roles, documentation
- **ISO Alignment Check**: Validates basic compliance
- **Enhanced Reporting**: Detailed DOCX generation

### Workflow Pattern

```
Input Procedure → Generator → Evaluator → Decision → Output
                     ↑           ↓
                     ←── Increment ←──
```

1. **Generator Node**: Reviews procedure against standards
2. **Evaluator Node**: Scores review quality (1-5 scale)
3. **Decision Node**: Continue if score < 4 or max iterations reached
4. **Output Node**: Returns final review

## Usage

### Basic Usage

```python
from procedure_review_agent import QualityReviewAgent
import os

# Initialize agent
agent = QualityReviewAgent(os.getenv("OPENAI_API_KEY"))

# Review procedure
result = agent.review_procedure(procedure_text, max_iterations=3)

# Generate report
report_file = agent.generate_report(result)
```

### Enhanced Usage

```python
from procedure_review_agent import EnhancedQualityReviewAgent

# Initialize enhanced agent
agent = EnhancedQualityReviewAgent(os.getenv("OPENAI_API_KEY"))

# Comprehensive review with analysis
result = agent.comprehensive_review(procedure_text, max_iterations=3)

# Generate enhanced report
report_file = agent.generate_enhanced_report(result)
```

## Features

### Token Usage Tracking
- **Input Tokens**: Tokens sent to LLM
- **Output Tokens**: Tokens generated by LLM
- **Total Tokens**: Combined count across all iterations

### Evaluation Criteria
- **Completeness**: Coverage of relevant ISO standards
- **Accuracy**: Correct references and interpretations
- **Specificity**: Actionable recommendations
- **Risk Assessment**: Risk management adequacy
- **Documentation**: Clear documentation requirements

### Report Generation
- Executive summary with scores
- Quick assessment table
- Detailed evaluation metrics
- Original procedure text
- Review findings and recommendations
- Standards reference appendix

## Configuration

### Environment Variables
```bash
OPENAI_API_KEY=your-openai-api-key-here
```

### Model Settings
- **Model**: gpt-4o-mini
- **Temperature**: 0.1 (for consistency)
- **Max Iterations**: 1-5 (configurable)

## Standards Coverage

### ISO 13485 - Medical Device Quality Management
- Document control procedures
- Management responsibility
- Resource management
- Product realization
- Measurement and improvement

### ISO 14971 - Risk Management
- Risk management process
- Risk analysis and evaluation
- Risk control measures
- Residual risk evaluation

### IEC 62304 - Software Life Cycle
- Software development planning
- Requirements analysis
- Architectural design
- Implementation and testing

## Output Structure

```python
{
    "input_procedure": "Original procedure text",
    "final_output": "Final review content",
    "evaluation_result": {
        "scores": {...},
        "overall_score": 4.2,
        "passed": True,
        "feedback": "..."
    },
    "iteration_count": 2,
    "token_usage": {
        "input_tokens": 1500,
        "output_tokens": 800,
        "total_tokens": 2300
    },
    "procedure_elements": {...},
    "iso_alignment": {...}
}
```

## Dependencies

- `langchain-openai`: OpenAI LLM integration
- `langchain-core`: Core LangChain components
- `langgraph`: Workflow orchestration
- `python-docx`: DOCX report generation
- `python-dotenv`: Environment variable management

## Error Handling

- **JSON Parsing**: Fallback evaluation scores if LLM response invalid
- **Token Tracking**: Graceful handling if usage metadata unavailable
- **File Operations**: Proper cleanup of temporary files

# Streamlit Quality Procedure Review App

A web-based interface for the Quality Procedure Review Agent that allows users to upload DOCX files, review procedures against ISO standards, and download comprehensive reports.

## Overview

The `streamlit_app.py` provides a user-friendly web interface that:
- Accepts DOCX procedure document uploads
- Processes documents through the AI review agent
- Displays real-time token usage and evaluation metrics
- Generates and provides downloadable DOCX reports

## Features

### 📋 Document Upload
- **File Type**: DOCX documents only
- **Text Extraction**: Automatic extraction from uploaded files
- **Preview**: Shows first 1000 characters of extracted text
- **Validation**: Error handling for corrupted files

### ⚙️ Configuration Panel
- **API Key Input**: Secure password field for OpenAI API key
- **Iteration Control**: Slider to set max review iterations (1-5)
- **Environment Support**: Reads from .env file if available

### 🔢 Token Usage Tracking
- **Input Tokens**: Number of tokens sent to LLM
- **Output Tokens**: Number of tokens generated by LLM
- **Total Tokens**: Combined count with comma formatting
- **Real-time Updates**: Updates after each review completion

### 📊 Evaluation Dashboard
- **Score Metrics**: 5 evaluation criteria with 1-5 scoring
- **Overall Score**: Weighted average with decimal precision
- **Visual Layout**: Organized in 3-column grid for readability

### 📄 Report Generation
- **Enhanced Reports**: Comprehensive DOCX with analysis
- **Download Button**: Direct download with descriptive filename
- **Cleanup**: Automatic temporary file removal

## User Interface

### Layout Structure
```
┌─────────────────────────────────────────────────────┐
│                    Page Header                      │
├─────────────────┬───────────────────────────────────┤
│   Upload Panel  │        Results Panel              │
│                 │                                   │
│ • File Upload   │ • Token Usage                     │
│ • Text Preview  │ • Evaluation Scores               │
│ • Start Review  │ • Review Findings                 │
│                 │ • Generate Report                 │
└─────────────────┴───────────────────────────────────┘
```

### Sidebar Configuration
- **API Key**: Password input with environment fallback
- **Max Iterations**: Slider control (1-5 range)
- **Validation**: Warning if API key missing

## Workflow

### 1. Setup Phase
```python
# Load environment variables
load_dotenv()

# Configure Streamlit page
st.set_page_config(
    page_title="Quality Procedure Review Agent",
    page_icon="📋",
    layout="wide"
)
```

### 2. Document Processing
```python
# Extract text from DOCX
def extract_text_from_docx(uploaded_file):
    doc = Document(uploaded_file)
    text = []
    for paragraph in doc.paragraphs:
        if paragraph.text.strip():
            text.append(paragraph.text)
    return '\n'.join(text)
```

### 3. Review Execution
```python
# Initialize and run agent
agent = EnhancedQualityReviewAgent(api_key)
result = agent.comprehensive_review(procedure_text, max_iterations)

# Store in session state
st.session_state.review_result = result
```

### 4. Results Display
- Token usage metrics in 3-column layout
- Evaluation scores with color-coded metrics
- Detailed review findings in text area
- Report generation with download capability

## Session State Management

### Stored Variables
- `review_result`: Complete agent output
- `procedure_text`: Extracted document text

### State Persistence
- Results persist across page interactions
- Automatic rerun after review completion
- Clean state management for new uploads

## Error Handling

### File Upload Errors
```python
try:
    procedure_text = extract_text_from_docx(uploaded_file)
    # Process successfully
except Exception as e:
    st.error(f"Error reading file: {str(e)}")
```

### Review Process Errors
```python
try:
    result = agent.comprehensive_review(procedure_text, max_iterations)
    st.success("Review completed!")
except Exception as e:
    st.error(f"Error during review: {str(e)}")
```

### Report Generation Errors
```python
try:
    report_filename = agent.generate_enhanced_report(result)
    # Provide download
    os.remove(report_filename)  # Cleanup
except Exception as e:
    st.error(f"Error generating report: {str(e)}")
```

## UI Components

### Metrics Display
```python
# Token usage metrics
st.metric("Input Tokens", f"{tokens['input_tokens']:,}")
st.metric("Output Tokens", f"{tokens['output_tokens']:,}")
st.metric("Total Tokens", f"{tokens['total_tokens']:,}")

# Evaluation scores
st.metric("Completeness", f"{score}/5")
st.metric("Overall Score", f"{overall:.1f}/5")
```

### Interactive Elements
- **File Uploader**: `st.file_uploader()` with DOCX filter
- **Text Areas**: `st.text_area()` for content preview and results
- **Buttons**: Primary and secondary styling for actions
- **Progress**: `st.spinner()` for long-running operations

## Configuration

### Environment Setup
```bash
# .env file
OPENAI_API_KEY=your-openai-api-key-here
```

### Streamlit Config
```python
st.set_page_config(
    page_title="Quality Procedure Review Agent",
    page_icon="📋",
    layout="wide"
)
```

## Dependencies

- `streamlit`: Web application framework
- `python-docx`: DOCX file processing
- `procedure_review_agent`: Core review functionality
- `python-dotenv`: Environment variable management
- `os`: File system operations

## Running the Application

### Local Development
```bash
# Install dependencies
pip install -r requirements.txt

# Set environment variables
cp .env.example .env
# Edit .env with your API key

# Run application
streamlit run streamlit_app.py
```

### Production Deployment
- Configure environment variables in hosting platform
- Ensure DOCX file upload limits are appropriate
- Set up proper error logging and monitoring

## File Operations

### Temporary File Management
```python
# Generate report
report_filename = agent.generate_enhanced_report(result)

# Read for download
with open(report_filename, 'rb') as file:
    report_data = file.read()

# Cleanup
os.remove(report_filename)
```

### Download Handling
```python
st.download_button(
    label="⬇️ Download Report",
    data=report_data,
    file_name=f"quality_review_report_{iterations}_iterations.docx",
    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
)
```
